{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "pd.options.display.float_format='{:.2f}'.format\n",
    "\n",
    "df = pd.read_csv('../data/000015', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)\n",
    "df['Return'] = df['Close'].pct_change() * 100\n",
    "df['Year'] = [i.year for i in df.index]\n",
    "df['Month'] = [i.month for i in df.index]\n",
    "df['Day'] = [i.day for i in df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing and computing descriptive statistics\n",
    "\n",
    "| Method           | Description                                                                                 |\n",
    "| ---------------- | ------------------------------------------------------------------------------------------- |\n",
    "| `count`          | Number of non-NA values                                                                     |\n",
    "| `describe`       | Compute set of summary statistics for Series or each DataFrame column                       |\n",
    "| `min, max`       | Compute minimum and maximum values                                                          |\n",
    "| `argmin, argmax` | Compute index locations (integers) at which minimum or maximum value obtained, respectively |\n",
    "| `idmin, idmax`   | Compute index values at which minimum or maximum value obtained, respectively               |\n",
    "| `quantile`       | Compute sample quantile ranging from 0 to 1                                                 |\n",
    "| `sum`            | Sum of values                                                                               |\n",
    "| `mean`           | Mean of values                                                                              |\n",
    "| `median`         | Arithmetic median (50% quantile) of values                                                  |\n",
    "| `mad`            | Mean absolute deviation from mean value                                                     |\n",
    "| `var`            | Sample variance of values                                                                   |\n",
    "| `std`            | Sample standard deviation of values                                                         |\n",
    "| `skew`           | Sample skewness (3rd moment) of values                                                      |\n",
    "| `kurt`           | Sample kurtosis (4th moment) of values                                                      |\n",
    "| `cumsum`         | Cumulative sum of values                                                                    |\n",
    "| `cummin, cummax` | Cumulative minimum or maximum of values, respectively                                       |\n",
    "| `cumprod`        | Cumulative product of values                                                                |\n",
    "| `diff`           | Compute 1st arithmetic difference (useful for time series)                                  |\n",
    "| `pct_change`     | Compute percent changes                                                                     |\n",
    "\n",
    "## Quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import mquantiles\n",
    "\n",
    "sorted_close = np.sort(df['Close'])\n",
    "mquantiles(sorted_close)\n",
    "\n",
    "[np.percentile(sorted_close, perc) for perc in [0, 25,50,75, 100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique values, value counts, and membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing - the null and alternative hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The null and alternative hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The alpha and p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type I and Type II errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format='{:.2f}'.format\n",
    "\n",
    "df1 = pd.read_csv('../data/000015', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)[-240:]\n",
    "df1['Return'] = df1['Close'].pct_change() * 100\n",
    "df2 = pd.read_csv('../data/000300', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)[-240:]\n",
    "df2['Return'] = df2['Close'].pct_change() * 100\n",
    "\n",
    "plt.scatter(df1['Return'], df2['Return'], marker='o', edgecolor='b', facecolor='none', alpha=0.5)\n",
    "plt.xlabel('000015')\n",
    "plt.ylabel('000300')\n",
    "\n",
    "slope, intercept = np.polyfit(df1['Return'][1:],df2['Return'][1:],1)\n",
    "plt.plot(df1['Return'],df1['Return']*slope + intercept,'r')\n",
    "plt.show()\n",
    "\n",
    "df3 = pd.concat([df1['Return'][1:], df2['Return'][1:]], axis=1)\n",
    "df3.columns = ['Return1', 'Return2']\n",
    "results = sm.ols('Return1 ~ Return2', df3).fit()\n",
    "results.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
