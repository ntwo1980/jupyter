{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "pd.options.display.float_format='{:.2f}'.format\n",
    "\n",
    "df = pd.read_csv('../data/000015', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)\n",
    "df['Return'] = df['Close'].pct_change() * 100\n",
    "df['Year'] = [i.year for i in df.index]\n",
    "df['Month'] = [i.month for i in df.index]\n",
    "df['Day'] = [i.day for i in df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prices = df[['Close', 'High', 'Low']]\n",
    "   \n",
    "series_close = df['Close']\n",
    "close_of_a_day = series_close['2010-01-04']\n",
    "close_of_a_day\n",
    "\n",
    "# can't get row of dataframe like:\n",
    "try:\n",
    "    df_prices['2010-01-04']\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing attributes using dot operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Close\n",
    "\n",
    "# select by specifying column indexes\n",
    "df[[1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range slicing\n",
    "\n",
    "The synttax of the slicing operator exactly matches that of NumPy:\n",
    "\n",
    "```python\n",
    "ar[startIndex: endIndex: stepValue]\n",
    "```\n",
    "\n",
    "where the default values if not specified are as follows:\n",
    "\n",
    "* 0 for startIndex\n",
    "* arraysize-1 for endIndex\n",
    "* 1 for stepValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label, integer and mixed indexing\n",
    "\n",
    "* The `.loc` operator: Allows label-oriented indexing\n",
    "* The `.iloc` operator: Allows integer-based indexing\n",
    "* The `.ix` operator: Allows mixed label and integer-based indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gg## Label-oriented indexing\n",
    "\n",
    "The `.loc` operator supports pure label-based indexing. It accepts the following as valid inputs:\n",
    "\n",
    "* A single label.\n",
    "* List or array of labels.\n",
    "* A slice object with labels.\n",
    "* A Boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['2010-01-04']\n",
    "\n",
    "# follows are same\n",
    "df.loc['2010-01-04', 'Close']\n",
    "df.loc['2010-01-04']['Close']\n",
    "df['Close']['2010-01-04']\n",
    "\n",
    "df.loc[['2010-01-04', '2010-01-05']]\n",
    "df.loc['2010-01-04': '2010-02-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection using a Boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df['Close'] <= df['Close'].min(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer-oriented indexing\n",
    "\n",
    "The `iloc` operator supports integer-based positional indexing. It accepts the following as inputs:\n",
    "\n",
    "* A single integer.\n",
    "* A list or array of integers.\n",
    "* A slice object with integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed indexing with the .ix opeator\n",
    "\n",
    "The `.ix` operator behaves like a mixture of the `.loc` and `.iloc` operators, with the `.loc` behavior taking precedence. It takes the following as possible inputs:\n",
    "\n",
    "* A single label or integer\n",
    "* A list of integers or labels\n",
    "* An integer slice or label slice\n",
    "* A Boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.ix['2010-01-04']\n",
    "df.ix[['2010-01-04', '2010-01-05']]\n",
    "df.ix[df.index[-3:]]\n",
    "df.ix[0]\n",
    "df.ix[[0, 2]]\n",
    "df.ix[1: 3]\n",
    "df.ix[df['Close'] > 4044.6640]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.reset_index()\n",
    "df1.set_index(['Year', 'Month', 'Day'], inplace=True)\n",
    "\n",
    "df1.index.get_level_values(0)\n",
    "df1.index.get_level_values(1)\n",
    "df1.index.get_level_values(2)\n",
    "\n",
    "df1.ix[2011, 2]\n",
    "df1.ix[2011: 2012]\n",
    "df1.ix[(2011, 1): (2012,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swapping and reordering levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_swapped = df1.swaplevel(0, 1, axis=0)\n",
    "df_swapped.sortlevel(0).ix[(1,2010):(1,2011)]\n",
    "\n",
    "# recorder_levels function is more general\n",
    "\n",
    "df_recorded = df1.reorder_levels(['Month', 'Day', 'Year'], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross sections\n",
    "\n",
    "The `xs` method provides a shortcut means of selecting data based on a particular index level value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.xs(2, level='Month')\n",
    "\n",
    "# same as \n",
    "\n",
    "df1.swaplevel(0, 1, axis=0).ix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\n",
    "obj.reindex(['a', 'b', 'c', 'd', 'e'], fill_value=0)\n",
    "\n",
    "obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])\n",
    "obj3.reindex(range(6), method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>4.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>7.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Texas  Utah  California\n",
       "a   1.00   nan        2.00\n",
       "b    nan   nan         nan\n",
       "c   4.00   nan        5.00\n",
       "d   7.00   nan        8.00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'],\n",
    "                  columns=['Ohio', 'Texas', 'California'])\n",
    "\n",
    "states = ['Texas', 'Utah', 'California']\n",
    "frame.reindex(index=['a', 'b', 'c', 'd'], method='ffill', columns=states)\n",
    "\n",
    "# reindex can be done by label-indexing with ix\n",
    "frame.ix[['a', 'b', 'c', 'd'], states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isin and any all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.index.isin(['2010-01-04', '2010-01-05'])]\n",
    "df.loc[(df.astype('int') == 2656).any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the where() method\n",
    "\n",
    "The `where` method is used to ensure that the result of Boolean filtering is the same shape as the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['Close'] > 2800]\n",
    "df.where(df > 2800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.reset_index()\n",
    "df1.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function application and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min())\n",
    "df.apply(lambda x: x.max() - x.min(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda x: pd.Series([x.min(), x.max()], index=['min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Element-wise apply\n",
    "df.applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the name `applymap` is that Series has a `map` method for applying an element-wise function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].map(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)\n",
    "\n",
    "df['Close'].sort_values()\n",
    "\n",
    "df.sort_values(by=['Year', 'Month'])\n",
    "\n",
    "df['Close'].rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The groupby operation\n",
    "\n",
    "The `groupby` operation can be thought of as part of a process that involves the following three steps:\n",
    "\n",
    "* Splitting the dataset\n",
    "* Analyzing the data\n",
    "* Aggregating or combining the data\n",
    "\n",
    "The result of a `groupby` operation is not a DataFrame but `dict` of DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Year'] = [i.year for i in df.index]\n",
    "df['Month'] = [i.month for i in df.index]\n",
    "df['Day'] = [i.day for i in df.index]\n",
    "\n",
    "df_group_by_year = df.groupby('Year')\n",
    "type(df_group_by_year)\n",
    "len(df_group_by_year)\n",
    "df_group_by_year.size().sort_values(ascending=False)\n",
    "\n",
    "df_group_by_year_month = df.groupby(['Year', 'Month'])\n",
    "df_group_by_year_month.size().sort_values(ascending=False)\n",
    "\n",
    "df_group_by_year = df.groupby(lambda x: x.year)\n",
    "#for name, group in df_group_by_year:\n",
    "#    print(name)\n",
    "#    print(group)\n",
    "\n",
    "df_index_year_month = df.reset_index()\n",
    "df_index_year_month = df_index_year_month.set_index(['Year', 'Month'])\n",
    "df_group_by_year = df_index_year_month.groupby(level=['Year', 'Month'])\n",
    "df_group_by_year.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using groupby with a MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_index_year_month = df.reset_index()\n",
    "df_index_year_month = df_index_year_month.set_index(['Year', 'Month'])\n",
    "\n",
    "grouped = df_index_year_month.groupby(level='Month')\n",
    "grouped.mean()\n",
    "# same as\n",
    "df_index_year_month.mean(level='Month')\n",
    "\n",
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the aggregate method\n",
    "\n",
    "Another way to generate summary statistics by using the aggregate method explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying multiple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.agg([np.sum, np.mean, np.size])\n",
    "\n",
    "grouped['Return'].agg({'Size': np.size, 'Total': np.sum, 'Average': np.mean, 'Deviation': np.std, 'Max': np.max, 'Min': np.min})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The transform() method\n",
    "\n",
    "The `groupby-transform` function is used to perform transormation operation on a `group` object. For example, we could replace NaN values in the `groupby` object using the `fillna` method. The resulting object after using the transform has the same size as the original `groupby` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "The `filter` method enables to apply filtering on a `groupby` object that results in a subset of the initial object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.filter(lambda x: np.all([x[col] > 1640 for col in ['High', 'Close', 'Low']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile and bucket analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closes = df['Close'][-240:]\n",
    "factor = pd.cut(closes, 10)\n",
    "\n",
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(), \n",
    "            'count': group.count(), 'mean': group.mean()}\n",
    "\n",
    "grouped = closes.groupby(factor)\n",
    "grouped.apply(get_stats).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using concat\n",
    "\n",
    "The `concat` function is used to join multiple pandas data structures along a specified axis and possibly perform union or intersection operations along other axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close']]\n",
    "df3 = df.ix['2010-01-06': '2010-01-9', ['High']]\n",
    "\n",
    "pd.concat([df1, df2, df3], axis=1) # outer join\n",
    "pd.concat([df1, df2, df3], axis=1, join='inner') # inner join\n",
    "pd.concat([df1, df2, df3], axis=1, join_axes=[df2.index]) # inner join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using append\n",
    "\n",
    "The `append` function is a simpler version of `concat` that concatenates along `axis=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close']]\n",
    "\n",
    "df1.append(df2).reindex_axis(df.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending a single row to a DataFrame\n",
    "\n",
    "A DataFrame can be appended a single row by passing a series or dictionary to the `append` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open', 'Close']]\n",
    "\n",
    "df1.append({'Open': 100, 'Close': 100}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data with overlap\n",
    "\n",
    "With DataFrames, `combine_first` can thought of as 'patching' missing dta the the calling object with data from the object passed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan], 'b': [np.nan, 2., np.nan, 6.], 'c': range(2, 18, 4)})\n",
    "df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.], 'b': [np.nan, 3., 4., 6., 8.]})\n",
    "\n",
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL-like merging/joining of DataFrame objects\n",
    "\n",
    "The `merge` function is used to obtain joins of two DataFrame objects similar to those used in SQL database queries. The DataFrame objects are analogous SQL tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open', 'High']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close', 'High']]\n",
    "\n",
    "pd.merge(df1, df2, how='inner')\n",
    "pd.merge(df1, df2, how='outer')\n",
    "pd.merge(df1, df2, how='left')\n",
    "pd.merge(df1, df2, how='right', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The join function\n",
    "\n",
    "The `DataFrame.join` function is used to combine two DataFrames that have different columns with nothing in common. Essentially, this does a longitudinal join of two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close']]\n",
    "\n",
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivots and reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and unstacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stack() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = df.stack(dropna=False)\n",
    "df.unstack('Date') # or df.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other methods to reshape DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the melt function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing data\n",
    "\n",
    "| Argument            | Description                                                                                                                                                                                                 |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `dropna`            | Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate.                                                                 |\n",
    "| `fillna`            | Fill in missing data with some value or using an interpolation method such as 'ffill' or 'bfill'.                                                                                                           |\n",
    "| `isnull`            | Return like-type object containing boolean values indicating which values are missing / NA.                                                                                                                 |\n",
    "| `notnull`           | Negation of `isnull`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.asfreq('D')\n",
    "\n",
    "df1.dropna()\n",
    "df1[df.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.fillna({'PE': -100, 'PB': 1000})\n",
    "\n",
    "df1.fillna(method='ffill', limit=2)\n",
    "df1.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n",
    "\n",
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'k1': ['one'] * 3 + ['two'] * 4, 'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "\n",
    "data.duplicated()\n",
    "data.drop_duplicates()\n",
    "data.drop_duplicates(['k1'])\n",
    "data.drop_duplicates(['k1', 'k2'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data using a function or mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami',\n",
    "                            'corned beef', 'Bacon', 'pastrami', 'honey ham',\n",
    "                            'nova lox'],\n",
    "                   'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "\n",
    "meat_to_animal = {\n",
    "    'bacon': 'pig',\n",
    "    'pulled pork': 'pig',\n",
    "    'pastrami': 'cow',\n",
    "    'corned beef': 'cow',\n",
    "    'honey ham': 'pig',\n",
    "    'nova lox': 'salmon'\n",
    "}\n",
    "\n",
    "data['animal'] = data['food'].map(str.lower).map(meat_to_animal)\n",
    "\n",
    "#or\n",
    "data['food'].map(lambda x: meat_to_animal[x.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "\n",
    "data.replace(-999, np.nan)\n",
    "data.replace([-999, -1000], np.nan)\n",
    "data.replace([-999, -1000], [np.nan, 0])\n",
    "data.replace({-999: np.nan, -1000: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming axis indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])\n",
    "\n",
    "data.index.map(str.upper)\n",
    "data.rename(index=str.title, columns=str.upper)\n",
    "data.rename(index={'OHIO': 'INDIANA'},columns={'three': 'peekaboo'})\n",
    "_ = data.rename(index={'OHIO': 'INDIANA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization and binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = pd.cut(df['Close'], 10, precision=2)\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = pd.qcut(df['Close'], 10, precision=2)\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and filtering outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "data = pd.DataFrame(np.random.randn(1000, 4))\n",
    "col = data[3]\n",
    "\n",
    "col[np.abs(col) > 3]\n",
    "data[(np.abs(data) > 3).any(1)]\n",
    "data[np.abs(data) > 3] = np.sign(data) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation and random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(5 * 4).reshape(5, 4))\n",
    "sampler = np.random.permutation(5)\n",
    "data.take(sampler)\n",
    "data.take(np.random.permutation(len(data))[:3])\n",
    "\n",
    "bag = np.array([5, 7, -1, 6, 4])\n",
    "sampler = np.random.randint(0, len(bag), size=10)\n",
    "draws = bag.take(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing indicator/dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataOffset and TimeDelta objects\n",
    "\n",
    "A `DateOffset` object represents a change or offset in time. The key features of a `DataOffset` object are as follows:\n",
    "\n",
    "* This can be added/subtracted to/from a `datetime` object to obtain a shifted date\n",
    "* This can be multiplied by an integer (positive or negative) so that the increment can be applied multiple times\n",
    "* This has the rollforward and rollback methods to move a date forward to the next offset date or backward to the previous offset date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmasDay = pd.datetime(2014, 12, 25)\n",
    "boxingDay = xmasDay + pd.DateOffset(days=1)\n",
    "today = pd.datetime.now()\n",
    "today + pd.DateOffset(weeks=1)\n",
    "today + 2 * pd.DateOffset(years=2, months=6)\n",
    "\n",
    "lastDay = pd.datetime(2013, 12, 31)\n",
    "from pandas.tseries.offsets import QuarterBegin\n",
    "dtoffset = QuarterBegin()\n",
    "lastDay + dtoffset\n",
    "dtoffset.rollforward(lastDay)\n",
    "\n",
    "weekDelta = dt.timedelta(weeks=1)\n",
    "today + weekDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series-related instance methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting/lagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].shift(3)\n",
    "df['Close'].shift(3, freq='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliases for Time Series frequencies\n",
    "\n",
    "To specify offsets, a number of aliases are available; some of the most commonly used ones are as follows:\n",
    "\n",
    "* B, BM: This stands for business day, business month. These are the working days of the month, that is, any day that is not a holiday or a weekend.\n",
    "* D, W, M, Q, A: It stands for calendar day, week, month, quarter, year-end.\n",
    "* H, T, S, L, U: It stands for hour, minute, second, millisecond, and microsecond.\n",
    "\n",
    "Suffixes can be applied to the frequency aliases to specify when in a frequency period to start. These are known as anchoring offsets:\n",
    "\n",
    "* W-Sun, MON,...\n",
    "* Q-JAN, FEB, ... DEC\n",
    "* A-JAN, FEB, ... DEC\n",
    "\n",
    "These offsets can be used as arguments to the `date_range` and `bdate_range` functions as well as constructors for index types such as `PeriodIndex` and `DatetimeIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series concepts and datatypes\n",
    "\n",
    "When dealing with time series, there are two main concepts: points in time and range, or time spans. In pandas, the former is represented by the Timestamp datatype, which is equivalent to Python's `datetime`. `datetime` datatype is interchangeable with it. The latter (time span) is represented by the Period datatype, which is specific to pandas.\n",
    "\n",
    "Each of these datatypes has index datatypes associated with them: `DatetimeIndex` for `Timestamp/Datetime` and `PeriodIndex` for `Period`. These index datatypes are basically subtypes of `numpy.ndarray` that contain the corresponding Timestamp and Period datatypes and can be used as indexes for Series and DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period and PeriodIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Period('2014', freq='A-May')\n",
    "pd.Period('2014-6-11')\n",
    "pd.Period('2014-6-11 11:00', freq='H')\n",
    "\n",
    "pd.Period('2014-6-11') + 4\n",
    "pd.Period('2014-6-11 11:00', freq='H') - 48\n",
    "\n",
    "pd.Period('2014-04', freq='M')-pd.Period('2013-02', freq='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PeriodIndex\n",
    "\n",
    "A `PeriodIndex` object, which is an index type for a `Period` object, can be created in two ways:\n",
    "\n",
    "* From series of `Period` objects using the `period_range` function, an analogue of `date_range`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perRng = pd.period_range('02/01/2014','02/06/2014',freq='D')\n",
    "perRng[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* It can also be done via direct call to the `Period` consturctor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JulyPeriod=pd.PeriodIndex(['07/01/2014','07/31/2014'], freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion between Time Series datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worldCupFinal = pd.to_datetime('07/13/2014', errors='raise')\n",
    "worldCupFinal.to_period('D')\n",
    "\n",
    "worldCupKickoff = pd.Period('06/12/2014','D')\n",
    "worldCupDays = pd.date_range('06/12/2014',periods=32, freq='D')\n",
    "worldCupDays.to_period()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a-summary-of-time-series-related-objects\n",
    "\n",
    "| Object              | Summary                                                                                                                                                                                                     |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `datetime.datetime` | Standard Python `datetime` class                                                                                                                                                                            |\n",
    "| `Timestamp`         | A pandas class derived from `datetime.datetime`                                                                                                                                                             |\n",
    "| `DatetimeIndex`     | A pandas class and implemented as an immutable `numpy.ndarray` of the `Timestamp/datetime` objects                                                                                                          |\n",
    "| `Period`            | A pandas class representing a time period                                                                                                                                                                   |\n",
    "| `timedelta`         | A pandas class expressing the difference between two `datetime.datetime` instances. It is implemented as `datetime.timedelta`                                                                               |\n",
    "| `relativedelta`     | Implemented as `dateutil.relativedelta`. dateutil is an extension to the standard Python datetime module. It provides extra functionality such as timedeltas that are expressed in units larger than 1 day. |\n",
    "| `DateOffset`        | A pandas class representing a regular frequency increment. It has similar functionality to `dateutil.relativedelta`.                                                                                        |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "860px",
    "left": "4px",
    "right": "732px",
    "top": "106px",
    "width": "263px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
