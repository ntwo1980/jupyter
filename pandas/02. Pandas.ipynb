{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format='{:.2f}'.format\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "df = pd.read_csv('../data/000015', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)\n",
    "df['Return'] = df['Close'].pct_change() * 100\n",
    "df['Year'] = [i.year for i in df.index]\n",
    "df['Month'] = [i.month for i in df.index]\n",
    "df['Day'] = [i.day for i in df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prices = df[['Close', 'High', 'Low']]\n",
    "   \n",
    "series_close = df['Close']\n",
    "close_of_a_day = series_close['2010-01-04']\n",
    "close_of_a_day\n",
    "\n",
    "# can't get row of dataframe like:\n",
    "try:\n",
    "    df_prices['2010-01-04']\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing attributes using dot operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Close\n",
    "%matplotlib inline\n",
    "# select by specifying column indexes\n",
    "df[[1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range slicing\n",
    "\n",
    "The synttax of the slicing operator exactly matches that of NumPy:\n",
    "\n",
    "```python\n",
    "ar[startIndex: endIndex: stepValue]\n",
    "```\n",
    "\n",
    "where the default values if not specified are as follows:\n",
    "\n",
    "* 0 for startIndex\n",
    "* arraysize-1 for endIndex\n",
    "* 1 for stepValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping entries from an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])\n",
    "obj.drop(['d', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['High', 'Low'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label, integer and mixed indexing\n",
    "\n",
    "* The `.loc` operator: Allows label-oriented indexing\n",
    "* The `.iloc` operator: Allows integer-based indexing\n",
    "* The `.ix` operator: Allows mixed label and integer-based indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gg## Label-oriented indexing\n",
    "\n",
    "The `.loc` operator supports pure label-based indexing. It accepts the following as valid inputs:\n",
    "\n",
    "* A single label.\n",
    "* List or array of labels.\n",
    "* A slice object with labels.\n",
    "* A Boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['2010-01-04']\n",
    "\n",
    "# follows are same\n",
    "df.loc['2010-01-04', 'Close']\n",
    "df.loc['2010-01-04']['Close']\n",
    "df['Close']['2010-01-04']\n",
    "\n",
    "df.loc[['2010-01-04', '2010-01-05']]\n",
    "df.loc['2010-01-04': '2010-02-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection using a Boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df['Close'] <= df['Close'].min(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer-oriented indexing\n",
    "\n",
    "The `iloc` operator supports integer-based positional indexing. It accepts the following as inputs:\n",
    "\n",
    "* A single integer.\n",
    "* A list or array of integers.\n",
    "* A slice object with integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed indexing with the .ix opeator\n",
    "\n",
    "The `.ix` operator behaves like a mixture of the `.loc` and `.iloc` operators, with the `.loc` behavior taking precedence. It takes the following as possible inputs:\n",
    "\n",
    "* A single label or integer\n",
    "* A list of integers or labels\n",
    "* An integer slice or label slice\n",
    "* A Boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.ix['2010-01-04']\n",
    "df.ix[['2010-01-04', '2010-01-05']]\n",
    "df.ix[df.index[-3:]]\n",
    "df.ix[0]\n",
    "df.ix[[0, 2]]\n",
    "df.ix[1: 3]\n",
    "df.ix[df['Close'] > 4044.6640]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.reset_index()\n",
    "df1.set_index(['Year', 'Month', 'Day'], inplace=True)\n",
    "\n",
    "df1.index.get_level_values(0)\n",
    "df1.index.get_level_values(1)\n",
    "df1.index.get_level_values(2)\n",
    "\n",
    "df1.ix[2011, 2]\n",
    "df1.ix[2011: 2012]\n",
    "df1.ix[(2011, 1): (2012,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swapping and reordering levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_swapped = df1.swaplevel(0, 1, axis=0)\n",
    "df_swapped.sortlevel(0).ix[(1,2010):(1,2011)]\n",
    "\n",
    "# recorder_levels function is more general\n",
    "\n",
    "df_recorded = df1.reorder_levels(['Month', 'Day', 'Year'], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross sections\n",
    "\n",
    "The `xs` method provides a shortcut means of selecting data based on a particular index level value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.xs(2, level='Month')\n",
    "\n",
    "# same as \n",
    "\n",
    "df1.swaplevel(0, 1, axis=0).ix[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\n",
    "obj.reindex(['a', 'b', 'c', 'd', 'e'], fill_value=0)\n",
    "\n",
    "obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])\n",
    "obj3.reindex(range(6), method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'],\n",
    "                  columns=['Ohio', 'Texas', 'California'])\n",
    "\n",
    "states = ['Texas', 'Utah', 'California']\n",
    "frame.reindex(index=['a', 'b', 'c', 'd'], method='ffill', columns=states)\n",
    "\n",
    "# reindex can be done by label-indexing with ix\n",
    "frame.ix[['a', 'b', 'c', 'd'], states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isin and any all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.index.isin(['2010-01-04', '2010-01-05'])]\n",
    "df.loc[(df.astype('int') == 2656).any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the where() method\n",
    "\n",
    "The `where` method is used to ensure that the result of Boolean filtering is the same shape as the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['Close'] > 2800]\n",
    "df.where(df > 2800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.reset_index()\n",
    "df1.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function application and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min())\n",
    "df.apply(lambda x: x.max() - x.min(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda x: pd.Series([x.min(), x.max()], index=['min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Element-wise apply\n",
    "df.applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the name `applymap` is that Series has a `map` method for applying an element-wise function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].map(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices = get_price(indexes, count = 240, end_date = t.today_str, fields=['high', 'close', 'low'])\n",
    "\n",
    "prices.swapaxes('items', 'minor')\n",
    "\n",
    "prices.to_frame().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)\n",
    "\n",
    "df['Close'].sort_values()\n",
    "\n",
    "df.sort_values(by=['Year', 'Month'])\n",
    "\n",
    "df['Close'].rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy mechanics\n",
    "\n",
    "### The groupby operation\n",
    "\n",
    "The `groupby` operation can be thought of as part of a process that involves the following three steps:\n",
    "\n",
    "* Splitting the dataset\n",
    "* Analyzing the data\n",
    "* Aggregating or combining the data\n",
    "\n",
    "The result of a `groupby` operation is not a DataFrame but `dict` of DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Year'] = [i.year for i in df.index]\n",
    "df['Month'] = [i.month for i in df.index]\n",
    "df['Day'] = [i.day for i in df.index]\n",
    "\n",
    "df_group_by_year = df.groupby('Year')\n",
    "type(df_group_by_year)\n",
    "len(df_group_by_year)\n",
    "df_group_by_year.size().sort_values(ascending=False)\n",
    "\n",
    "df_group_by_year_month = df.groupby(['Year', 'Month'])\n",
    "df_group_by_year_month.size().sort_values(ascending=False)\n",
    "\n",
    "df_group_by_year = df.groupby(lambda x: x.year)\n",
    "#for name, group in df_group_by_year:\n",
    "#    print(name)\n",
    "#    print(group)\n",
    "\n",
    "df_index_year_month = df.reset_index()\n",
    "df_index_year_month = df_index_year_month.set_index(['Year', 'Month'])\n",
    "df_group_by_year = df_index_year_month.groupby(level=['Year', 'Month'])\n",
    "df_group_by_year.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (year, month), group in df.groupby(['Year', 'Month']):\n",
    "    print(year, month)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pieces = dict(list(df.groupby('Year')))\n",
    "pieces[2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a column or subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['Year', 'Month'])[['Close']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with dicts and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people = pd.DataFrame(np.random.randn(5, 5),\n",
    "    columns=['a', 'b', 'c', 'd', 'e'],\n",
    "    index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])\n",
    "people.ix[2:3, ['b', 'c']] = np.nan # Add a few NA values\n",
    "\n",
    "mapping = {'a': 'red', 'b': 'red', 'c': 'blue',\n",
    "           'd': 'blue', 'e': 'red', 'f' : 'orange'}\n",
    "\n",
    "by_column = people.groupby(mapping, axis=1)\n",
    "by_column.sum()\n",
    "\n",
    "map_series = pd.Series(mapping)\n",
    "people.groupby(map_series, axis=1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people.groupby(len).sum()\n",
    "\n",
    "key_list = ['one', 'one', 'one', 'two', 'two']\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by index levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_index_year_month = df.reset_index()\n",
    "df_index_year_month = df_index_year_month.set_index(['Year', 'Month'])\n",
    "\n",
    "grouped = df_index_year_month.groupby(level='Month')\n",
    "grouped.mean()\n",
    "# same as\n",
    "df_index_year_month.mean(level='Month')\n",
    "\n",
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('Year')['Close'].quantile(np.arange(0,1.1,0.1)).unstack()\n",
    "df.groupby('Year')['Close'].describe().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the aggregate method\n",
    "\n",
    "Another way to generate summary statistics by using the aggregate method explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying multiple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.agg([np.sum, np.mean, np.size])\n",
    "\n",
    "grouped['Return'].agg({'Size': np.size, 'Total': np.sum, 'Average': np.mean, 'Deviation': np.std, 'Max': np.max, 'Min': np.min})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning aggregated data in \"unindexed\" form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['Year'], as_index=False).mean()\n",
    "# the reulst is possible to obtain by calling reset_index on result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-wise operations and transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The transform() method\n",
    "\n",
    "The `groupby-transform` function is used to perform transormation operation on a `group` object. For example, we could replace NaN values in the `groupby` object using the `fillna` method. The resulting object after using the transform has the same size as the original `groupby` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['Year', 'Month'])['Close'].transform(lambda x: (x - x.mean()) /x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply: general split-apply-combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top(df, n=5, column='Close'):\n",
    "    return df.sort_values(by=column)[-n:]\n",
    "\n",
    "df.groupby('Year').apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppressing the group keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('Year', group_keys=False).apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing values with group-specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(6))\n",
    "s[::2] = np.nan\n",
    "\n",
    "s.fillna(s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = ['Ohio', 'New York', 'Vermont', 'Florida',\n",
    "    'Oregon', 'Nevada', 'California', 'Idaho']\n",
    "\n",
    "group_key = ['East'] * 4 + ['West'] * 4\n",
    "data = pd.Series(np.random.randn(8), index=states)\n",
    "data[['Vermont', 'Nevada', 'Idaho']] = np.nan\n",
    "\n",
    "data.groupby(group_key).mean()\n",
    "\n",
    "fill_mean = lambda g: g.fillna(g.mean())\n",
    "data.groupby(group_key).apply(fill_mean)\n",
    "\n",
    "fill_values = {'East': 0.5, 'West': -1}\n",
    "fill_func = lambda g: g.fillna(fill_values[g.name])\n",
    "data.groupby(group_key).apply(fill_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random sampling and permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suits = ['H', 'S', 'C', 'D']\n",
    "card_val = (list(range(1, 11)) + [10] * 3) * 4\n",
    "base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q']\n",
    "cards = []\n",
    "for suit in ['H', 'S', 'C', 'D']:\n",
    "    cards.extend(str(num) + suit for num in base_names)\n",
    "\n",
    "deck = pd.Series(card_val, index=cards)\n",
    "\n",
    "def draw(deck, n=5):\n",
    "    return deck.take(np.random.permutation(len(deck))[:n])\n",
    "\n",
    "draw(deck)\n",
    "\n",
    "get_suit = lambda card: card[-1]\n",
    "\n",
    "deck.groupby(get_suit, group_keys=False).apply(draw, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group weighted average and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'category': ['a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'],\n",
    "    'data': np.random.randn(8), 'weights': np.random.rand(8)})\n",
    "\n",
    "grouped = df.groupby('category')\n",
    "get_wavg = lambda g: np.average(g['data'], weights=g['weights'])\n",
    "grouped.apply(get_wavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "close_px = pd.read_csv('ch09/stock_px.csv', parse_dates=True, index_col=0)\n",
    "rets = close_px.pct_change().dropna()\n",
    "spx_corr = lambda x: x.corrwith(x['SPX'])\n",
    "by_year = rets.groupby(lambda x: x.year)\n",
    "\n",
    "by_year.apply(spx_corr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group-wise linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```python\n",
    "import statsmodels.api as sm\n",
    "def regress(data, yvar, xvars):\n",
    "    Y = data[yvar]\n",
    "    X = data[xvars]\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params\n",
    "\n",
    "by_year.apply(regress, 'AAPL', ['SPX'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "The `filter` method enables to apply filtering on a `groupby` object that results in a subset of the initial object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.filter(lambda x: np.all([x[col] > 1640 for col in ['High', 'Close', 'Low']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile and bucket analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closes = df['Close'][-240:]\n",
    "factor = pd.cut(closes, 10)\n",
    "\n",
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(), \n",
    "            'count': group.count(), 'mean': group.mean()}\n",
    "\n",
    "grouped = closes.groupby(factor)\n",
    "grouped.apply(get_stats).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using concat\n",
    "\n",
    "The `concat` function is used to join multiple pandas data structures along a specified axis and possibly perform union or intersection operations along other axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close']]\n",
    "df3 = df.ix['2010-01-06': '2010-01-9', ['High']]\n",
    "\n",
    "pd.concat([df1, df2, df3], axis=1) # outer join\n",
    "pd.concat([df1, df2, df3], axis=1, join='inner') # inner join\n",
    "pd.concat([df1, df2, df3], axis=1, join_axes=[df2.index]) # inner join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using append\n",
    "\n",
    "The `append` function is a simpler version of `concat` that concatenates along `axis=0`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close']]\n",
    "\n",
    "df1.append(df2).reindex_axis(df.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending a single row to a DataFrame\n",
    "\n",
    "A DataFrame can be appended a single row by passing a series or dictionary to the `append` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open', 'Close']]\n",
    "\n",
    "df1.append({'Open': 100, 'Close': 100}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data with overlap\n",
    "\n",
    "With DataFrames, `combine_first` can thought of as 'patching' missing dta the the calling object with data from the object passed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan], 'b': [np.nan, 2., np.nan, 6.], 'c': range(2, 18, 4)})\n",
    "df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.], 'b': [np.nan, 3., 4., 6., 8.]})\n",
    "\n",
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL-like merging/joining of DataFrame objects\n",
    "\n",
    "The `merge` function is used to obtain joins of two DataFrame objects similar to those used in SQL database queries. The DataFrame objects are analogous SQL tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open', 'High']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close', 'High']]\n",
    "\n",
    "pd.merge(df1, df2, how='inner')\n",
    "pd.merge(df1, df2, how='outer')\n",
    "pd.merge(df1, df2, how='left')\n",
    "pd.merge(df1, df2, how='right', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The join function\n",
    "\n",
    "The `DataFrame.join` function is used to combine two DataFrames that have different columns with nothing in common. Essentially, this does a longitudinal join of two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.ix['2010-01-04': '2010-01-10', ['Open']]\n",
    "df2 = df.ix['2010-01-05': '2010-01-12', ['Close']]\n",
    "\n",
    "df1.join(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivots and reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and unstacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stack() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = df.stack(dropna=False)\n",
    "df.unstack('Date') # or df.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pivoting \"long\" to \"wide\" format\n",
    "\n",
    "A common way to store multiple time series in databases and CSV is in so-called *long* or *stacked* format.\n",
    "\n",
    "|        | date                | item    | value       |\n",
    "| ------ | ------------------- | ------- | ----------- |\n",
    "| 0      | 1959-03-31 00:00:00 | realgdp | 2710.349    |\n",
    "| 1      | 1959-03-31 00:00:00 | infl    | 0.000       |\n",
    "| 2      | 1959-03-31 00:00:00 | unemp   | 5.800       |\n",
    "| 3      | 1959-06-30 00:00:00 | realgdp | 2778.801    |\n",
    "| 4      | 1959-06-30 00:00:00 | infl    | 2.340       |\n",
    "| 5      | 1959-06-30 00:00:00 | unemp   | 5.100       |\n",
    "| 6      | 1959-09-30 00:00:00 | realgdp | 2775.488    |\n",
    "| 7      | 1959-09-30 00:00:00 | infl    | 2.740       |\n",
    "| 8      | 1959-09-30 00:00:00 | unemp   | 5.300       |\n",
    "| 9      | 1959-12-31 00:00:00 | realgdp | 2785.204    |\n",
    "\n",
    "DateFrame's `pivot` method performs exactly trasformation:\n",
    "\n",
    "```python\n",
    "pivoted = ldata.pivot('date', 'item', 'value')\n",
    "```\n",
    "\n",
    "| item       | infl | realgdp  | unemp |\n",
    "| ---------- | ---- | -------- | ----- |\n",
    "| date       |      |          |       |\n",
    "| 1959-03-31 | 0.00 | 2710.349 | 5.8   |\n",
    "| 1959-06-30 | 2.34 | 2778.801 | 5.1   |\n",
    "| 1959-09-30 | 2.74 | 2775.488 | 5.3   |\n",
    "| 1959-12-31 | 0.27 | 2785.204 | 5.6   |\n",
    "| 1960-03-31 | 2.31 | 2847.699 | 5.2   |\n",
    "\n",
    "The first two values passed are columns to be used as the row and column index, and finally an optional value column to fill the DataFrame. Suppose there are two value columns that are to be reshape simulataneously:\n",
    "\n",
    "```python\n",
    "ldata['value'] = np.random.randn(len(ldata))\n",
    "```\n",
    "\n",
    "By ommitting the last argument, a DataFrame with hierarchical columns is got:\n",
    "\n",
    "```python\n",
    "pivoted = ldata.pivot('date', 'item')\n",
    "pivoted['value'][:5]\n",
    "pivoted['value2'][:5]\n",
    "```\n",
    "\n",
    "Note that `pivot` is just shortcut for creating a hierarchical index using `set_index` and reshaping with `unstack`:\n",
    "\n",
    "```python\n",
    "unstacked = ldata.set_index(['data', 'item']).unstack('item')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.pivot_table(['Return'], index=['Year'], columns=['Month'], aggfunc=np.mean, margins=True, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.pivot_table('Return', index=['Year'], columns=['Month'], aggfunc=sum, margins=True, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-tabulations: crosstab\n",
    "\n",
    "A cross-tabulation is a special case of a pivot table that computes group frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab([df['Year'], df['Month']], df['Day'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other methods to reshape DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the melt function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing data\n",
    "\n",
    "| Argument            | Description                                                                                                                                                                                                 |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `dropna`            | Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate.                                                                 |\n",
    "| `fillna`            | Fill in missing data with some value or using an interpolation method such as 'ffill' or 'bfill'.                                                                                                           |\n",
    "| `isnull`            | Return like-type object containing boolean values indicating which values are missing / NA.                                                                                                                 |\n",
    "| `notnull`           | Negation of `isnull`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.asfreq('D')\n",
    "\n",
    "df1.dropna()\n",
    "df1[df.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.fillna({'PE': -100, 'PB': 1000})\n",
    "\n",
    "df1.fillna(method='ffill', limit=2)\n",
    "df1.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n",
    "\n",
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'k1': ['one'] * 3 + ['two'] * 4, 'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "\n",
    "data.duplicated()\n",
    "data.drop_duplicates()\n",
    "data.drop_duplicates(['k1'])\n",
    "data.drop_duplicates(['k1', 'k2'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data using a function or mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami',\n",
    "                            'corned beef', 'Bacon', 'pastrami', 'honey ham',\n",
    "                            'nova lox'],\n",
    "                   'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "\n",
    "meat_to_animal = {\n",
    "    'bacon': 'pig',\n",
    "    'pulled pork': 'pig',\n",
    "    'pastrami': 'cow',\n",
    "    'corned beef': 'cow',\n",
    "    'honey ham': 'pig',\n",
    "    'nova lox': 'salmon'\n",
    "}\n",
    "\n",
    "data['animal'] = data['food'].map(str.lower).map(meat_to_animal)\n",
    "\n",
    "#or\n",
    "data['food'].map(lambda x: meat_to_animal[x.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "\n",
    "data.replace(-999, np.nan)\n",
    "data.replace([-999, -1000], np.nan)\n",
    "data.replace([-999, -1000], [np.nan, 0])\n",
    "data.replace({-999: np.nan, -1000: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming axis indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])\n",
    "\n",
    "data.index.map(str.upper)\n",
    "data.rename(index=str.title, columns=str.upper)\n",
    "data.rename(index={'OHIO': 'INDIANA'},columns={'three': 'peekaboo'})\n",
    "_ = data.rename(index={'OHIO': 'INDIANA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization and binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = pd.cut(df['Close'], 10, precision=2)\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = pd.qcut(df['Close'], 10, precision=2)\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and filtering outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "data = pd.DataFrame(np.random.randn(1000, 4))\n",
    "col = data[3]\n",
    "\n",
    "col[np.abs(col) > 3]\n",
    "data[(np.abs(data) > 3).any(1)]\n",
    "data[np.abs(data) > 3] = np.sign(data) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation and random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(5 * 4).reshape(5, 4))\n",
    "sampler = np.random.permutation(5)\n",
    "data.take(sampler)\n",
    "data.take(np.random.permutation(len(data))[:3])\n",
    "\n",
    "bag = np.array([5, 7, -1, 6, 4])\n",
    "sampler = np.random.randint(0, len(bag), size=10)\n",
    "draws = bag.take(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing indicator/dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataOffset and TimeDelta objects\n",
    "\n",
    "A `DateOffset` object represents a change or offset in time. The key features of a `DataOffset` object are as follows:\n",
    "\n",
    "* This can be added/subtracted to/from a `datetime` object to obtain a shifted date\n",
    "* This can be multiplied by an integer (positive or negative) so that the increment can be applied multiple times\n",
    "* This has the rollforward and rollback methods to move a date forward to the next offset date or backward to the previous offset date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmasDay = pd.datetime(2014, 12, 25)\n",
    "boxingDay = xmasDay + pd.DateOffset(days=1)\n",
    "today = pd.datetime.now()\n",
    "today + pd.DateOffset(weeks=1)\n",
    "today + 2 * pd.DateOffset(years=2, months=6)\n",
    "\n",
    "lastDay = pd.datetime(2013, 12, 31)\n",
    "from pandas.tseries.offsets import QuarterBegin\n",
    "dtoffset = QuarterBegin()\n",
    "lastDay + dtoffset\n",
    "dtoffset.rollforward(lastDay)\n",
    "\n",
    "weekDelta = dt.timedelta(weeks=1)\n",
    "today + weekDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting between string and datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stamp = dt.datetime(2011, 1, 3)\n",
    "str(stamp)\n",
    "value = stamp.strftime('%Y-%m-%d')\n",
    "\n",
    "dt.datetime.strptime(value, '%Y-%m-%d')\n",
    "\n",
    "from dateutil.parser import parse\n",
    "parse('2011-01-03')\n",
    "parse('Jan 31, 1997 10:45 PM')\n",
    "parse('6/12/2011', dayfirst=True)\n",
    "\n",
    "datestrs = ['7/6/2011', '8/6/2011']\n",
    "pd.to_datetime(datestrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series-related instance methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.date_range('1/1/2000', '12/1/2000', freq='BM')\n",
    "pd.date_range('5/2/2012 12:56:31', periods=5, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting(leading and lagging) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].shift(3)\n",
    "df['Close'].shift(3, freq='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting dates with offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "\n",
    "now = dt.datetime(2017, 1, 1)\n",
    "now + 3 * Day()\n",
    "now + MonthEnd(2)\n",
    "\n",
    "offset = MonthEnd()\n",
    "offset.rollforward(now)\n",
    "offset.rollback(now)\n",
    "\n",
    "df['Close'].groupby(offset.rollforward).mean()\n",
    "df['Close'].resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.resample('W').bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open-High-Low-Close(OHLC) resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].resample('M').ohlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling with groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].groupby(lambda x: (x.year, x.month)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliases for Time Series frequencies\n",
    "\n",
    "To specify offsets, a number of aliases are available; some of the most commonly used ones are as follows:\n",
    "\n",
    "* B, BM: This stands for business day, business month. These are the working days of the month, that is, any day that is not a holiday or a weekend.\n",
    "* D, W, M, Q, A: It stands for calendar day, week, month, quarter, year-end.\n",
    "* H, T, S, L, U: It stands for hour, minute, second, millisecond, and microsecond.\n",
    "\n",
    "Suffixes can be applied to the frequency aliases to specify when in a frequency period to start. These are known as anchoring offsets:\n",
    "\n",
    "* W-Sun, MON,...\n",
    "* Q-JAN, FEB, ... DEC\n",
    "* A-JAN, FEB, ... DEC\n",
    "\n",
    "These offsets can be used as arguments to the `date_range` and `bdate_range` functions as well as constructors for index types such as `PeriodIndex` and `DatetimeIndex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series concepts and datatypes\n",
    "\n",
    "When dealing with time series, there are two main concepts: points in time and range, or time spans. In pandas, the former is represented by the Timestamp datatype, which is equivalent to Python's `datetime`. `datetime` datatype is interchangeable with it. The latter (time span) is represented by the Period datatype, which is specific to pandas.\n",
    "\n",
    "Each of these datatypes has index datatypes associated with them: `DatetimeIndex` for `Timestamp/Datetime` and `PeriodIndex` for `Period`. These index datatypes are basically subtypes of `numpy.ndarray` that contain the corresponding Timestamp and Period datatypes and can be used as indexes for Series and DataFrame objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period and period arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Period('2014', freq='A-May')\n",
    "pd.Period('2014-6-11')\n",
    "pd.Period('2014-6-11 11:00', freq='H')\n",
    "\n",
    "pd.Period('2014-6-11') + 4\n",
    "pd.Period('2014-6-11 11:00', freq='H') - 48\n",
    "\n",
    "pd.Period('2014-04', freq='M')-pd.Period('2013-02', freq='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PeriodIndex\n",
    "\n",
    "A `PeriodIndex` object, which is an index type for a `Period` object, can be created in two ways:\n",
    "\n",
    "* From series of `Period` objects using the `period_range` function, an analogue of `date_range`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perRng = pd.period_range('02/01/2014','02/06/2014',freq='D')\n",
    "perRng[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* It can also be done via direct call to the `Period` consturctor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JulyPeriod = pd.PeriodIndex(['07/01/2014','07/31/2014'], freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Period frequency conversion\n",
    "\n",
    "Periods and `PeriodIndex` objects can be converted to another frequency using their `asfreq`method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = pd.Period('2007', freq='A-JUN')\n",
    "\n",
    "p.asfreq('M', how='start')\n",
    "p.asfreq('M', how='end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = pd.period_range('2006', '2009', freq='A-DEC')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "\n",
    "ts.asfreq('M', how='start')\n",
    "ts.asfreq('B', how='end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quarterly period frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = pd.Period('2012Q4', freq='Q-JAN')\n",
    "p.asfreq('D', 'start')\n",
    "p.asfreq('D', 'end')\n",
    "\n",
    "p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60\n",
    "p4pm.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = pd.period_range('2011Q3', '2012Q4', freq='Q-JAN')\n",
    "ts = pd.Series(np.arange(len(rng)), index=rng)\n",
    "new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60\n",
    "ts.index = new_rng.to_timestamp()\n",
    "\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion between Time Series datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worldCupFinal = pd.to_datetime('07/13/2014', errors='raise')\n",
    "worldCupFinal.to_period('D')\n",
    "\n",
    "worldCupKickoff = pd.Period('06/12/2014','D')\n",
    "worldCupDays = pd.date_range('06/12/2014',periods=32, freq='D')\n",
    "worldCupDays.to_period()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].rolling(window=39).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially-weighted functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Close'].ewm(span=39).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary moving window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/000300', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)\n",
    "df2 = pd.read_csv('../data/000015', index_col= 'Date', names=['Date', 'Open', 'Close', 'High', 'Low', 'Volume', 'Money', 'PE', 'PB'], parse_dates=True, header=None)\n",
    "\n",
    "df1['Return'] = df1['Close'].pct_change()\n",
    "df2['Return'] = df2['Close'].pct_change()\n",
    "\n",
    "corr = df1['Return'].rolling(window=125, min_periods=100).corr(df2['Return'])\n",
    "corr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use-defined moving window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "\n",
    "score_at_2percent = lambda x: percentileofscore(x, 0.1)\n",
    "df['Return'].rolling(window=39).apply(score_at_2percent).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## a-summary-of-time-series-related-objects\n",
    "\n",
    "| Object              | Summary                                                                                                                                                                                                     |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `datetime.datetime` | Standard Python `datetime` class                                                                                                                                                                            |\n",
    "| `Timestamp`         | A pandas class derived from `datetime.datetime`                                                                                                                                                             |\n",
    "| `DatetimeIndex`     | A pandas class and implemented as an immutable `numpy.ndarray` of the `Timestamp/datetime` objects                                                                                                          |\n",
    "| `Period`            | A pandas class representing a time period                                                                                                                                                                   |\n",
    "| `timedelta`         | A pandas class expressing the difference between two `datetime.datetime` instances. It is implemented as `datetime.timedelta`                                                                               |\n",
    "| `relativedelta`     | Implemented as `dateutil.relativedelta`. dateutil is an extension to the standard Python datetime module. It provides extra functionality such as timedeltas that are expressed in units larger than 1 day. |\n",
    "| `DateOffset`        | A pandas class representing a regular frequency increment. It has similar functionality to `dateutil.relativedelta`.                                                                                        |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "860px",
    "left": "7px",
    "right": "732px",
    "top": "105px",
    "width": "263px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
